

# 事务

## MVCC
> 多版本并发控制

为了提高数据库并发性能，用更好的方式去处理读写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读
MVCC 基于版本链和 ReadView 实现

### 版本链
> 每个版本链针对的是一条数据

MySQL 聚簇索引中有三个隐藏字段（每行数据中都有）
- `DB_TRX_ID`：最后一次修改这条数据的事务ID
- `DB_ROLL_PTR`：每次对某条聚簇索引的记录修改，都把旧版本写入 UndoLog，这个隐藏字段相当于一个指针，指向 UndoLog 中上一个数据版本
- `DB_ROW_ID`：隐藏的主键，如果数据表没有主键，自动生成一个6字节的 row_id

![image-20230317014154050](C:\backup\assets\image-20230317014154050.png)

不同事务对同一记录的修改，导致此记录的 UndoLog 形成一个版本链，下面图片实例模拟版本链的生成

![image-20230317014217953](C:\backup\assets\image-20230317014217953.png)

![image-20230317014206999](C:\backup\assets\image-20230317014206999.png)

![image-20230317014250397](C:\backup\assets\image-20230317014250397.png)

对于使用未提交读隔离级别的事务，由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好了（不需要MVCC）
对于使用可串行化隔离级别的事务，加锁解决（不需要MVCC)

### ReadView
Read View 用来做可见性判断的，作用于快照读，有三个全局属性：
- `trx_list`：记录 Read View 生成时活跃的事务ID列表
- `up_limit_id`：记录 trx_list 列表中最小值
- `low_limit_id`：记录 Read View 生成尚未分配的下一个事务ID（PS：事务ID递增分配）

遍历版本链的比较规则（关键的是第三个判断）：

1. 判断`DB_TRX_ID < up_limit_id`
   1. 是：当前事务能看到 DB_TRX_ID 所在的记录
   2. 否：进入下一个判断
2. 判断`DB_TRX_ID >= low_limit_id`
   1. 是：代表 DB_TRX_ID 所在的记录在 Read View  生成后才出现的，对于当前事务肯定不可见，继续遍历
   2. 否：进入下一步判断
3. 判断`DB_TRX_ID in trx_list`
   1. 是：当前事务不应该看到活跃事务的修改，继续遍历
   2. 否：说明这个历史记录对当前事务可见
### RC解决脏读
> RC：READ COMMITTED 读已提交

**读已提交隔离级别的事务，每个快照读都生成一个 ReadView**
如果进入第三个判断，如果这个记录被活跃事务修改了，当前事务是不可见的，继续遍历；这种机制下就避免了脏读问题
但有不可重复读问题，因为已经提交的事务不再是活跃事务，它的修改记录对当前事务可见

### RR解决不可重复读
RR 隔离级别的事务，**只有首次快照读生成 ReadView**，之后的快照读将重复利用这个 ReadView
这样的话，其他事务提交之后还是被当作了活跃事务处理，其修改对当前事务是不可见的，因此解决了不可重复读问题

### RR解决幻读问题
快照读：如果一直使用快照读，不可能读到其他事务新增的数据，自行分析
当前读：如果第一次是快照读，第二次是当前读，可能发生幻读，因为当前读没有利用MVCC

总结一下就是：
- 如果事务中都是快照读，不可能产生幻读
- **快照读和当前读一起使用时可能产生幻读，应该避免**
- 如果事务中都是当前读，通过临键锁来解决幻读问题

## UndoLog
用来保证事务的原子性

此外 MVCC 的版本链就是 UndoLog

## 锁

> 标签：锁

### 共享锁(S)与排它锁(X)

共享锁允许其他事务读，不允许写
排它锁都不允许

S兼容S
S不兼容X
X不兼容X

### 行锁与表锁
InnoDB 的行锁是给索引项加锁；只有真正通过索引检索数据，InnoDB 才使用行锁，否则使用表锁
行锁分为记录锁、间隙锁、临键锁=记录锁+间隙锁
间隙锁和临键锁用于解决幻读问题

```shell
#记录锁
#等值查询，锁定单行记录

#间隙锁
#当查询的记录不存在，无论是用等值查询还是范围查询的时候，它使用的都是间隙锁，锁定记录间隙

#临键锁
#范围查询，不仅仅命中了记录，还包含了间隙，使用的就是临键锁，它是默认的行锁算法，相当于记录锁加上间隙锁
#select * from t2 where id >5 and id =7 for update; 锁住 (4,7] 和 (7,10]
#select * from t2 where id >8 and id =10 for update; 锁住 (7,10] 和 (10,+∞)
#Mysql8不再锁下个区间
```

![image-20230416230020978](C:\backup\assets\image-20230416230020978.png)

### 意向锁
意向锁是表锁，分为意向共享锁、意向排它锁，它们的提出仅仅为了在之后加表级别的共享锁和排它锁时可以快速判断表中是否有行锁，以避免用遍历的方式来查看表中有没有上锁的记录
## **

## 隐式提交
如果开启自动提交`autocommit=ON`，输入了某些语句之后就自动提交
如果关闭自动提交`autocommit=OFF`，或使用`START TRANSACTION`、`BEGIN`开启了一个事务，事务不进行自动提交

## 快照读、当前读
快照读：读取的不一定是最新记录，也有可能是某个历史记录；普通的查询是快照读，不加锁
当前读：读取的是最新记录，且对读取的记录加锁，保证其他并发事务不能修改当前记录；当前读的例子如下

- `select lock in share mode`共享锁
- `select for update`排它锁
- `update`排它锁
- `insert`排它锁
- `delete`排它锁

==update、insert、delete这些操作为什么是当前读？==
1、假设当前事务先快照读
    2、其他事务再新增提交
        3、当前事务再更新数据，如果更新操作快照读就更新不了已经被其他事务提交的记录

BinLog 中当前事务更新操作在其他事务提交之后，同步到 slave 中数据是不一致，slave 中更新了其他事务提交的记录
## 幻读可能带来什么问题
TODO
## BufferPool
BufferPool（缓存池）用来缓存表数据与索引数据，减少磁盘IO
缓存池中存储的是一个个缓存页（16K），每个缓存页都有一个控制块，采用链表来管理数据页

空闲的缓存页（Free Page）对应的控制块都存入一个链表中，称作==Free链表==
访问某页的数据时，缓存池中有的话直接读取；没有的话从磁盘读取此页加载到缓存池中，从 Free链表中取出一个空闲的缓存页加载，并将其对应的控制块移出链表

==如何判断缓存池中有没有某个页？==为已加载的缓存页建立一个哈希表，key为表空间号+页号，value为缓存页对应的控制块
当需要访问某个页的数据时，先从哈希表中根据表空间号+页号看看是否存在对应的缓冲页
如果有，则直接使用；如果没有，就从Free链表中选出一个空闲的缓存页，然后把磁盘中对应的页加载进来...

修改过的页（dirty page）的控制块存储存储在一个==Flush链表==中，在未来某个时间刷盘

缓存淘汰有一个==LRU链表==，新访问过缓存页的控制块调整到链首，缓存不够用的时候淘汰链尾的缓存页
但是数据库提供了预读，读入的某些缓存页可能一次都没有用过，都放入链首的话可能导致热点缓存页比这些无用的缓存页先淘汰，这将大大降低缓存命中率；解决办法就是将 LRU 链表分为两截 Young 和 Old，预读时先将缓存页的控制块存入 Old 区首部（Old 区空间不够时尾部的无用缓存页被淘汰），Old 区的缓存页被访问就会被当作热点数据移动到 Young 区的首部
![image-20230416101736756](C:\backup\assets\image-20230416101736756.png)

并发访问各种链表都需要加锁处理，因此拆分为多个小的缓冲池，提高并发能力（类似于 ConcurrentHashmap 的桶）

### 预读

磁盘读写，并不是按需读取，而是按页读取，如果未来要读取的数据就在页中，就能够省去后续的磁盘IO，提高效率

### ChangeBuffer

如果 DML 操作请求的==辅助索引（二级索引）==没有在缓存池中，并不会立刻将磁盘页加载到缓存池，而是在 ChangeBuffer 记录变更，等未来数据被读取时，再将数据合并恢复到 BufferPool 中

为什么只针对辅助索引呢？因为唯一索引在进行修改时必须要做唯一性校验，因此必须查询磁盘做一次IO操作，会直接将记录查询到 BufferPool 中，然后在缓存池修改，不会在 ChangeBuffer 操作

## BinLog
BinLog 记录的是所有修改操作，是逻辑日志，用来备份数据和主备同步数据

想要做到主备数据一致就得保证 RedoLog 和 BinLog 的一致性，因此 RedoLog 的写入使用两阶段提交【如下图】
prepare 阶段 RedoLog 写入磁盘，然后 BinLog 写入磁盘，最后事务提交

![image-20230317014411168](C:\backup\assets\image-20230317014411168.png)

> 上图有个错误点：应该是先写 redolog 再更新缓存

在 BC 两个点可能宕机出现数据不一致的问题，怎么解决？
重启后如果发现 RedoLog 处于 prepare 状态，就通过事务ID 检查 BinLog 是否包含此条 RedoLog 的内容，如果不包含 RedoLog 丢弃此次变更，如果包含事务将提交

# 索引

## **

## B+树进化史

==为什么不用《哈希索引》==

- 只能定位单条数据，无法做到范围查询
- 数据量很大时，哈希冲突概率也会非常大
- 不支持利用索引排序

==树→二叉树→二叉查找树==

二叉查找树效率高，类似二分查找，二叉查找树符合以下几点：
1、左子树的所有的值小于根节点的值
2、右子树的所有的值大于或等于根节点的值

但是如果设计不好，可能形成一个不平衡的二叉查找树，树的深度太深影响查询效率

==平衡二叉树==

是一棵二叉查找树，左右两个子树的高度差不超过1，左右两个子树都是一棵平衡二叉树
维护一棵平衡二叉树的代价是非常大的

==B+树==

由二叉平衡树演化而来
是一颗多叉树，树的高度远低于平衡二叉树，减少了磁盘IO次数
只有叶子节点存储数据，叶子节点由小到大（物理无序、逻辑有序、指针相连）串联在一起，叶子页中的数据也是排好序的

![image-20230406192412064](C:\backup\assets\image-20230406192412064.png)

==为什么不用B树？==
B树每个节点都存储数据，相同数据规模下将增加磁盘IO次数，相比下来B+树磁盘IO次数少
B+树采取顺序读，B树是随机读
B+树能提高范围查询的效率，因为叶子节点指向下一个叶子节点

# 执行计划

执行计划查看具体执行查询的方式

语法：`EXPLAIN select * from table1`

## id

每个 SELECT 关键字都对应一个 id

单SELECT关键字就不说了

==连接查询==
多个 SELECT 关键字，在连接查询的执行计划中，每个表都对应一条记录，这些记录的 id 列的值是相同的
![image-20230406195139236](C:\backup\assets\image-20230406195139236.png)

==包含子查询==
多个 SELECT 关键字
特别的情况：查询优化器可能对涉及子查询的查询语句进行重写，转换为连接查询
下面例子是一个子查询，但是执行计划中两个表对应的记录的 id 值都是1，这表明查询优化器将子查询转换为了连接查询
![image-20230406195301217](C:\backup\assets\image-20230406195301217.png)

==包含UNION子句==
多个 SELECT 关键字
特别的情况：合并结果集的时候需要去重（id=NULL）
![image-20230406195354855](C:\backup\assets\image-20230406195354855.png)

==UNION ALL==
不需要去重
![image-20230406195421227](C:\backup\assets\image-20230406195421227.png)

## table

表名

## partitions

和分区表有关，一般情况下执行计划的 partitions 列的值都是 NULL

## type

访问类型，是较为重要的一个指标，出现比较多的是：`system > const > eq_ref > ref > range > index > ALL`（从好到坏）

### system

innodb 引擎没有这种情况出现

### const

根据主键或唯一二级索引与常数进行等值匹配时，对单表的访问类型就是 const，因为只匹配一行数据，所以很快
![image-20230406195509646](C:\backup\assets\image-20230406195509646.png)

如果主键或唯一二级索引是由多个列构成的话，组成索引的每一个列都是与常数进行等值比较时，这个 const 访问类型才有效

### eq_ref

在连接查询时，如果被驱动表是通过主键或唯一二级索引列等值匹配的方式进行访问的，则对该被驱动表的访问类型就是 eq_ref
如果主键或唯一二级索引是联合索引，所有的索引列都必须进行等值比较
![image-20230406195531796](C:\backup\assets\image-20230406195531796.png)

### ref

通过普通的二级索引列与常量进行等值匹配时来查询某个表，访问类型可能是 ref（匹配到多条记录）
如果匹配的记录较少，则回表的代价还是比较低的，所以可能选择使用索引而不是全表扫描的方式来执行查询

### range

使用索引进行范围查询的类型是 range，比全表扫描好

### index

当我们可以使用索引覆盖，但需要扫描全部的索引记录时，访问类型就是 index
![image-20230406195544740](C:\backup\assets\image-20230406195544740.png)

这里是联合索引，但是查询条件不是最左匹配，无法走索引

即扫描的是索引但是索引其实没有生效

### ALL

全表扫描

## possible_keys&key

possible_keys 表示对某个表执行单表查询时可能用到的索引有哪些
key 表示实际用到的索引有哪些，NULL 代表没有使用索引

## key_len

表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度，计算方式是这样的：

- 对于固定长度类型的索引列，最大长度就是这个固定值
- 对于 VARCHAR(100)【utf8】，最大长度是100 x 3 = 300个字节
- 对于变长字段来说，都会有2个字节的空间来存储该变长列的实际长度
- 如果索引列可以存储 NULL 值，则 key_len 比不可以存储 NULL 值时多1个字节
## rows

如果查询优化器决定使用**全表扫描**，rows 就代表预计需要扫描的行数（不是得到的结果条数）
如果用索引来执行查询时，rows 就代表预计扫描的索引记录行数
![image-20230406195702622](C:\backup\assets\image-20230406195702622.png)

## filtered

代表本次查询完之后被过滤得到的数据占比是多少
比如下图：代表驱动表s1 扫描10573条记录，扇出值是10573 x 33.33 % = 3524.3，说明还要对被驱动表执行大约3524次查询
![image-20230406195716147](C:\backup\assets\image-20230406195716147.png)

## Extra

| xx                    | yy                                                           |
| --------------------- | ------------------------------------------------------------ |
| Using index           | 表示直接访问索引就能够获取到所需要的数据（覆盖索引），不需要通过索引回表 |
| Using join buffer     | 使用了连接缓存，会显示连接查询时 MySQL 选择的查询算法        |
| Using filesort        | 无法利用索引完成的排序操作称为“文件排序”                     |
| Using index condition | 搜索条件中有索引列，但是有部分条件无法使用索引，会根据能用索引的条件先搜索一遍再匹配无法使用索引的条件 |
|                       |                                                              |



# 索引合并（单表）

## Intersection合并&Union合并

Intersection 是交集合并，Union 是并集合并
```sql
SELECT * FROM order_exp WHERE order_no = 'a' AND(OR) expire_time = 'b';
```
![image-20230406201333385](C:\backup\assets\image-20230406201333385.png)

假如这个查询使用索引合并的话，过程如下：
1、从`idx_order_no`索引中取出`order_no='a'`的相关记录
2、从`idx_expire_time`索引中取出`expire_time='b'`的相关记录
3、计算两个结果集中 id 的交集
4、回表，从聚簇索引中把指定 id 值的记录取出来

==为啥不单独使用某个二级索引，回表后再过滤另外的条件呢？==

这里要分析一下两种查询执行方式之间需要的成本代价

只读取一个二级索引的成本：
1、按照某个搜索条件读取一个二级索引
2、回表
3、过滤其他的搜索条件

读取多个二级索引之后取交集成本：
1、按照不同的搜索条件分别读取不同的二级索引
2、主键值取交集
3、最后根据主键值进行回表操作

读取多个二级索引比读取一个二级索引消耗性能，但是大部分情况下读取二级索引的操作是顺序IO而回表操作是随机IO，需要比较两种查询方式消耗的时间了

==数据库什么情况下用合并：二级索引等值匹配==
二级索引列必须是等值匹配的情况
对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况
都是为了取出的结果集是按主键值排序的

```sql
-- 因为对order_no进行了范围匹配
SELECT * FROM order_exp WHERE order_no > 'a' AND expire_time = 'a';
-- 因为insert_time使用到的联合索引u_idx_day_status中的order_status和expire_time列并没有出现在搜索条件中
SELECT * FROM order_exp WHERE order_no = 'a' AND insert_time = 'a';
```
==数据库什么情况下用合并：主键列范围匹配==
因为主键的索引是有序的，按照有序的主键值回表开销不大
PS：二级索引范围查询的话得到的结果不是根据主键排序的，在求主键交集之前需要先排序比较耗时

上边两种情况只是可能发生而不是必然，是否走索引合并得看优化器的心情，优化器预测耗时比较之后抉择

## Sort-Union合并

上述索引合并条件苛刻，必须是等值匹配才行
```sql
SELECT * FROM order_exp WHERE order_no < 'a' OR expire_time > 'z'
```
上面的语句就不能使用 Union 索引合并，因为主键不是排好序的

可以这样做（比 Union 合并多了一步主键排序的过程）
1、根据第一个条件使用索引获取记录，并按照记录的主键值排序
2、根据第二个条件使用索引获取记录，并按照记录的主键值排序
3、主键值求并集
4、回表

也不是必然的，得看优化器的心情

## 联合索引代替Intersection合并

没有 Intersection 合并，可以使用联合索引代替

# 连接查询与优化

```sql
SELECT * FROM e1, e2 WHERE e1.m1 > 1 AND e1.m1 = e2.m2 AND e2.n2 < 'd';
```
连接查询的步骤：
1、确定驱动表，第一个需要查询的表
2、遍历驱动表结果，到被驱动表中查找匹配记录
![image-20230406201205799](C:\backup\assets\image-20230406201205799.png)

上面的例子需要查询1次驱动表、两次被驱动表
==结论：两表连接查询，需要查询1次驱动表、多次被驱动表；小表做驱动表更好==

内连接时：驱动表中的数据只有在被驱动表中有匹配记录，才加入结果集
外连接时：驱动表中的数据即使在被驱动表中没有匹配记录，也需要加入结果集（左连接左表为驱动表、右连接右表为驱动表)

可以优化一下对驱动表的查询，如果可以的话，这里不谈
被驱动表全表扫描很慢，可以在被驱动表的相关字段建立索引（只有二级索引+回表代价比全表扫描低时才走索引）
如果实在不能利用索引，那就要利用好 JoinBuffer（缓冲区），调整合适的缓冲区大小来优化（降低被驱动表的扫描次数）
（PS：只有查询列表的列和查询条件中的列才进入缓冲区，因此一定要杜绝使用`select *`）
![image-20230419225740824](C:\backup\assets\image-20230419225740824.png)

# 做过MySQL优化吗

不是在出现了问题之后再优化，首先需要做一些预防，比如
1、表的创建：可以适当的允许冗余字段，以空间换时间；《字段数据类型的优化》；《创建高性能的索引》
2、通过 profile、慢查询等相关方式来监控 SQL 语句和数据库的状态

出问题的话从执行计划、索引优化、SQL优化、参数调整等方面来调优

# 修改参数生效吗

参数有 session 和 global 级别的，在客户端修改参数重启不会生效，只有在配置文件中配置重启才会生效

# 使用索引一定可以提升效率吗？

1、对于增删改操作，维护索引反而会降低执行速度
2、对于查询操作，如果利用到了索引将会提升效率，但是也有例外
3、有时候走索引反而会降低效率，比如数据量很少的时候，优化器会选择全表扫描

# 介绍一下Page页的结构

Page 是整个 InnoDB 磁盘管理的最小单位

Page 分为几种类型，常见的页类型有数据页（B+tree Node）、Undo页、系统页、事务数据页等

页结构整体上可以分为三大部分：分别为通用部分、存储记录空间、索引部分
==通用部分==：主要指文件头和文件尾，将页的内容封装，通过文件头和文件尾校验的 CheckSum 方式来确保页的传输是完整的
其中比较重要的是在文件头中的`FIL_PAGE_PREV`和`FIL_PAGE_NEXT`字段，通过这两个字段，我们可以找到该页的上一页和下一页，所有页通过这两个字段可以形成一条双向链表
==记录部分==：页的主要作用是存储记录，“最小和最大记录”和“用户记录”部分占了页结构的主要空间；另外当有新的记录插入时，会从空闲空间中进行分配用于存储新记录
==数据目录部分==：数据页中行记录按照主键值由小到大顺序串联成一个单链表，且单链表的链表头为最小记录，链表尾为最大记录；为了更快速地定位到指定的行记录，借助 `Page Directory`使用二分法快速找到需要查找的行记录
![image-20230416115801011](C:\backup\assets\image-20230416115801011.png)

# InnoDB与MyISAM的区别

|          |  InnoDB  |   MyISAM   |
| :------: | :------: | :--------: |
|   事务   |   支持   |   不支持   |
|   外键   |   支持   |   不支持   |
|  行级锁  |   支持   |   不支持   |
|  表级锁  |   支持   |    支持    |
| 索引结构 | 聚簇索引 | 非聚簇索引 |

# 顺序IO&随机IO

一次磁盘IO时间 = 寻道时间 + 旋转延迟 + 数据传送时间

顺序IO 的旋转延迟极低，随机IO 的旋转延迟是随机的可能很高

# B+树能存储多少个索引记录

MySQL B+树的节点大小等于一个页（16K），这样做的目的是每个节点只需要一次 IO 就可以完全载入

假设主键是 bigint 8字节，指针6字节，根节点可以存储索引数量 16k / 14 = 1170，第二层可以存储索引数量 1170 * 1170

假设一行数据是1K，一个叶子节点能存储 16 条数据

三层 B+ 树能够存储  1170 * 1170 * 16 大约 2000万数据

# 查询语句是怎么执行的

![83a5d762-27eb-486e-b22f-193d2bb847dc](C:\backup\assets\83a5d762-27eb-486e-b22f-193d2bb847dc.png)

1、建立连接

解析器：词法分析、语法分析，生成解析树
预处理器：根据一些 MySQL 规则进一步检查解析树是否合法，例如检查数据表和数据列是否存在，还会解析名字和别名，看看它们是否有歧义，最后生成新的解析树
查询优化器：生成并选择最优的执行计划 TODO 具体干啥了
执行器：操作引擎，返回结果

关于查询缓存：5.7支持，8之后废弃

# 更新语句是怎么执行的

看《binlog》

# RedoLog与BinLog的区别

RedoLog 是物理日志，BinLog 是逻辑日志

RedoLog 是 InnoDB 引擎特有的，BinLog 是 MySQL 的 Server 层实现的，所有引擎都可以使用

RedoLog 是循环写的，BinLog 是追加写

用途不一样

# 如何优化深分页

TODO

# 写失效与双写机制

InnoDB 的页（16K）和操作系统的页（4K）大小不一致，InnoDB 一个页写入磁盘需要分4次写
如果写了一半宕机了，这种情况叫做部分写失效，可能会导致数据丢失

双写机制解决了写失效问题
在 BufferPool 的脏页刷新到磁盘前，会先写入磁盘中共享表空间的双写缓冲区（是一个文件相当于备份），完成后再真正刷盘
如果宕机出现数据页损坏，重启后利用双写缓冲区的备份数据修复损坏的数据页，然后再进行 RedoLog 重做

![image-20230426140745132](C:\backup\assets\image-20230426140745132.png)
