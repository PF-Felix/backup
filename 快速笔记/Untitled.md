数据库的存储引擎基本上是两个存储引擎合二为一。

第一个是时间序列数据库，基本上，它有一个时间序列一个值和时间戳的集合按时间排序，我们在时间序列上做压缩之类的事情。

然后是一个倒排索引。通常说到倒排索引，你会想到搜索数据库，对吧？它们将词映射到文档id，并使用反向索引快速查找哪些文档匹配哪些搜索词。
在我们的例子中，我们将时间序列元数据与我们拥有的时间序列进行匹配。

在我介绍实际的存储引擎之前，我需要介绍一下，我们是如何在influinum中构建数据的。

所以很明显，所有的东西都是由时间和它的序列索引的。

所以在数据库中，我们也有分片的概念，基本上就是时间块。在这个例子中，我们每天有一个分片。

<img src="D:\Felix\快速笔记\assets\image-20230915002605558.png" alt="image-20230915002605558" style="zoom: 67%;" />

现在某一天的所有时间序列数据都存在于这张图表中。这样一来，如果我们想要删除旧数据，就会变得很有效。



所以问题是，我们为什么要创造自己的引擎？对吧？

首先，我们使用了 LSM trees。具体来说，我们使用了一个级别数据库，这是一个嵌入式数据库。它是Google编写的a-c++库，它被称为长结构合并树。现在，椭球测量法被大大优化了。他们的速度非常非常快。他们也做压缩。我们尝试了，在项目的第一年，我不知道，大概一年半的时间，我们使用了底层数据库，也就是底层数据存储，我们也尝试了一些变体。稍后。我们尝试了hyperlevelDB，这是它的一个分支。我们尝试了rocksDB，它是loveDB的一个分支，开发了一个Facebook。当我们刚开始制作《涌入》时，石头还不存在。异位测定的一个问题是删除非常非常昂贵。

因此，当您执行删除操作时，实际上是将一个墓碑记录写入磁盘。之后，当你查询时，你需要用墓碑解析数据库中的键以返回实际结果。然后，会运行一个压缩过程重写你的ss表来删除那条记录，对吧？所以基本上，要删除一条记录，你最终会重写一堆其他的记录，这可能会很昂贵。

我们遇到的另一个问题是，正如我提到的，我们把我们的数据组织成时间碎片。我们的做法是为每个时间段创建一个新的关卡DB数据库。这一开始并不是一个问题，但对于那些拥有非常非常大的数据库或时间跨度非常大的用户来说，他们最终会在这个过程中打开的文件句柄数量过多。所以我们用完了文件描述符。所以我们也尝试了内存对内存，映射复制，B+树，对吧？这是第一个版本的mongodbB吗？是这个吗？Go中有一个叫做boltDB的库，我们使用的就是这个库。很大程度上受到了L-M-D-B的启发。复制到右边。Pplustories非常酷。他们。他们很好，但是右传球对他们来说真的很糟糕。它们没有针对繁重的工作负载进行优化。我们发现，一开始，正确的吞吐量是相当不错的，然后随着数据库规模的增长，它会变得越来越慢，甚至更糟，它会像你看到的那样，挤占我们磁盘上的操作。我希望眼压峰值能达到20000，还有各种疯狂的东西。另一个对我们来说很麻烦的地方是bulk，它会对内存映射文件进行大小调整，每次它开始过度增长，它就会过度增长，它会将文件的大小翻倍，对吧？所以当你从02:506mb增长到05:12mb时，这并不是什么大问题。但是当我们达到千兆字节甚至几百兆字节的规模时，它会冻结整个数据库。什么撤销文件，太糟糕了。

另一件对我们来说也很重要的事情是这个存储引擎没有内置的压缩功能，为了节省时间，压缩是非常非常重要的.

我们需要的是高速写入。优秀的读取

我们需要一种高支撑的东西。我们有很好的读取性能，这是时间序列的奇怪之处。这就像是数据库最糟糕的用例，因为你不仅有很高的正确吞吐量，你也有来自所有仪表板系统和监控系统的高需求吞吐量，只是一直用范围请求冲击数据库。呃？我们需要压缩性能更好的东西。

我们研究了不同的压缩时间序列数据的技术，我们发现我们可以实现比Snappy这样的通用算法更好的压缩。所以我们要优化它。我们需要一些权利不会阻碍芦苇和阅读阻碍权利的东西。我们宁愿读取陈旧的数据，也不愿拥有进入系统的读块权限。关于时间序列数据的另一件事是它很大程度上只是一个附加的工作量。你没有更新，对吧？你只是依赖于新的数据。您是否在对历史数据进行回填？它一直在移动。如果你做一个读取，它有点陈旧，你说的是微秒，或者毫秒，或者秒。请求里可没提到这一点。所以我们还需要能够同时写出多个值域。嗯。我们提到的其中一个用例很多是传感器数据，在很多传感器数据场景中，你有滞后数据收集，对吧？所以他们会在当地收集，它们会传输数据，比如每小时一次，每4小时一次，或者每天一次。所以我们知道在任何给定的时间，在数据库中可能有不同时间范围内发生的权利有点接近现在，但可能会关闭，并且可以支持热备份。在时间层面上，我不认为在这一点上，支持备份，热备份。但岩石确实如此。但在当时，我们没有选择。呃？我们需要在一个进程中同时打开多个数据库，而不会导致系统崩溃。

所以大约一年半前，我们开始创建我们自己的存储注意力，我们称之为时间结构合并树，它的灵感很大程度上来自于 LSM，但它有一点不同。

<img src="D:\Felix\快速笔记\assets\image-20230915004524578.png" alt="image-20230915004524578" style="zoom:67%;" />

这里是商店引擎的不同组成部分。我们有一个正向日志，我们有一个内存现金，我们有只读的索引文件。这非常非常类似于所有世纪的结构，对吧？对吧？头日志。相同的概念在Lsmtry的DB级别，它被称为表。在DB层，它叫做ss表，对吧？但它们基本上是一样的，对吧？当我们把数据写入存储引擎时，我们有很长的时间，大量的数据进入。我们把它写到墙上，写到内存中，内存中可以查询的数据结构，然后我们在此时将响应发送回客户端，因为我们知道right是持久的，它可以立即对芦苇可用。然后周期性地在内存中进行刷新，索引到我们所说的TSM文件，基本上就是那些ss表，有索引的文件，有一个特定的结构，是只读文件，我们也对这些文件进行内存映射，这样我们就可以像在数组中一样访问它们。但更重要的是，我们让操作系统为我们处理现金，对吗？我们让它在内存中翻页，这样我们就不用自己写所有的逻辑了。通过内存映射文件，我们可以免费得到一堆东西。

TSM文件是这样的。我们有一个header，我们有数据块，我们有索引，然后我们有一个footer。

<img src="D:\Felix\快速笔记\assets\image-20230915004808684.png" alt="image-20230915004808684" style="zoom: 33%;" />

<img src="D:\Felix\快速笔记\assets\image-20230915004908052.png" alt="image-20230915004908052" style="zoom:50%;" />

<img src="D:\Felix\快速笔记\assets\image-20230915004925015.png" alt="image-20230915004925015" style="zoom: 33%;" />

<img src="D:\Felix\快速笔记\assets\image-20230915004955970.png" alt="image-20230915004955970" style="zoom:50%;" />

header是这样的。你有魔力，神奇的四口告诉你这是什么样的文件。然后我们有一个版本。

积木是这样的，对吧？我们有一个数据块的集合，我们有一个CRC，然后我们有实际的数据，其中的数据被压缩了，给定序列的时间序列数据，对吧？然后如果我们有一个新的级数，就会有一个新的方块。实际上，即使是给定的序列，我们也不会一次压缩它的所有数据，我将在第二次讨论

然后我们有一个索引，所以我们可以看到键长度，键本身，它是一个字符串键，对吧测量名称，税在字段中，我们有文件中的值的数量，同时在最大时间内。我们使用它的基本原理是，当一个查询来寻找一个特定的时间范围时，我们可以很快地找到哪些紫罗兰在秋天，在秋天的什么地方。

最后，我们有一个页脚它告诉我们索引的起始位置。基本上，当我们有那个内存映射文件时，我们知道我们看数组的最后四个字节，我们可以跳转到索引所在的位置，我们可以在索引上做一些事情就好像它是一个内存结构，对吧？我们可以做搜索之类的。这就是压缩块的样子。你有一个类型，这是我们在64中支持的字段的类型，浮点64，金块和字符串，这实际上与其他时间序列数据库有很大不同。许多其他时间序列数据库只允许存储数字，而且通常是一种特定类型的数字，要么是浮点数64，要么是64。然后我们有时间戳和值。所以这就是我说的，我们，我们，我们把严肃的数据分成块，因为我们把时间戳和值分开，因为我们可以实现更好的压缩。因此，默认情况下，我们将把多达一千个值时间戳对编码到单个这些块中。所以如果一个请求是一个单一的值，我们实际上最终解码了一千个值，对吧？看一下压缩，时间戳，我们是根据精度和它们之间的差来编码的，对吧？所以我们支持纳秒级的精度，但是仅仅因为我们支持它并不意味着我们需要表示所有的低阶位如果它们都是零，对吧？所以在最好的情况下，我们可以使用运行长度和编码作为时间戳。如果你有一个规则的时间序列你每10秒采样一次？你只需要二级精度，所以你所需要做的就是存储初始的起始时间戳和它们之间的增量，你知道，就像，我们有，我们可以在运行中从那个信息构造任何时间戳。在O-K的情况下，我们使用一种叫做简单a-b的压缩技术。它是从这篇论文中提取出来的，并使用64位字进行索引压缩。嗯？所以在这种情况下它看起来有点像双增量编码，对吧？所以时间戳不是固定的。它们不是固定的收集时间间隔。它们可以是可变的，对吧？它们可能会有一秒或两微秒或几毫秒的抖动。所以在最坏的情况下，我们实际上必须存储原始值。我们必须存储完整的64个时间戳。这是在人们使用纳秒级时间戳的情况下出现的，但是每个时间戳之间的距离太大，不能用delta来表示，或者，表示它的成本不仅仅是存储原始时间戳本身。所以对于浮点64压缩，我们使用双增量技术。这和Facebook大猩猩的论文很相似。在2015年夏天，facebook发表了一篇关于大猩猩的论文，这是他们内部的度量系统。它用这个，嗯，这个压缩技术，来计算它们的流量值。他们说他们可以把数据压缩到，取决于数据的形状，每个压缩到大约1。1比特他们使用32位时间戳，这和我们的不一样。它们还会将时间戳和数值交织在一起，这是我们不会做的。所以我们稍微改变了一下。嗯。jamie和Grisky，他是很有名的go语言开发者，在论文发表后，他写了一个实现，我们把它分叉，做了一些我们需要的修改。的情况。金条或比特。这些都很简单，对吧？在64中，我们使用双三角或之字形编码。之字形与原始的buff字符串相同。我们只用Snappy。我们正在考虑稍后添加字典压缩，但现在snappy已经足够了。所以更新。我们可以更新值。这不是我们要优化的，但基本上，如果数据库中的任何值与测量名称，标签，设置字段和纳秒时间戳相关联？因此，在任何给定的序列键和纳秒级时间戳中只能有一个值。所以如果你写另一个有相同信息的值，它就会取代原来的值。所以本质上，我们在查询时通过消除旧的副本来解决这个问题。然后，当压缩过程运行时，它会抛出旧值并保留新值，即删除。这与elcenty非常相似。我们在查询时在契约中写入墓碑。我们用从内存索引中的索引中读取的数据解析墓碑。之后的压缩将重写TSM文件并删除已删除的数据。压缩基本上就是把多个TSM文件合并成一个更大的TSM文件。嗯。我们的目标是将同一个系列中的尽可能多的点放到一个文件中，对吧？这样它们就可以连续运行。这样，我们就可以对数据进行快速的降雨扫描并进行计算。对吧？我在一个K块中提到点，我们有多个级别的压缩，我们首先优先考虑较低的级别，然后再考虑较大的级别。另一件事是，当我们压缩数据时，我们将TSM文件按时间顺序排列。它们有时间范围。如果你现在写数据，你一直在挂起新数据。那些旧文件会被压缩到一定程度，然后它们就不会被碰触。对吧？我们将只涉及年轻一代的SM文件。但因为我们有碎片的概念，碎片通常会在一段时间后冷却。因此，过一段时间后，我们将尝试对该碎片进行全面的同情，它将查看所有TSM文件并尝试优化，以获得最佳组合。

好了，现在谈谈我们的索引方案。所以这是通过这个walk来看这个示例查询，这样我们就能了解问题的范围，对吧？因此，在此查询中，我们仅从西部地区的主机中获取过去12小时的CPU测量值的第90个百分位数，并且我们需要10分钟的桶，并且我们需要每个主机的系列。对吧？呃？现在的问题是，我们如何映射这个元数据，这个度量，被命名为cpu主机区域，到底层序列，这样我们就可以执行这个计算并返回一堆单独的时间序列。我们用的是倒排索引，对吧？一种看待它的方式，就像我们现在对内存索引做的那样，我们有那些系列键，也就是字符串，它映射了唯一的ID。我们需要看看有哪些测量值，我们稍后可以绘制哪些场。我们需要查看哪些主机，我们有哪些值，正确的标签键host，以及该区域的唯一值，我们有哪些区域，然后我们需要保持发布列表的正确性。在CPU测量下出现了什么想法，在每个标签键值下出现了什么想法？之后，当你整理数据时，你可以做一些像联合和交叉这样的事情，来找出你需要处理的严肃想法的列表。index=1，也就是当前版本中的值，也就是1。点2在内存中？我们在启动时加载它。我们有了所有底层的SM文件。当数据库启动时，它会查看这些文件，查看每个文件中的系列键，并在内存索引中建立这个。这意味着，第一，你的记忆力明显受限，对吧？在你的数据库中，你只能保留尽可能多的唯一序列在内存索引中。但是，如果基数非常大，也可能出现启动时间较慢的情况。所以你可以有大量的内存，但是，你知道，在一个系统中，你知道，几百gb的内存，它需要很长时间来启动并将那么多数据读取到内存中。对吧？所以我们对索引的目标是我们想要一些既在磁盘上又在内存里的东西，就像一个组合。我们在这里试图解决的关键问题是我们有很多用例其中时间序列是短暂的，对吧？因此，如果你正在考虑跟踪，呃，容器指标或单个过程指标，并且你希望容器ID或过程ID在像那些短暂的标签中，对吗？您可以让流程运行几个小时，几天，然后它就会消失，您可以稍后查询它，但很可能它不在您的工作集中。它消失后，对查询或权利来说就不热了。所以我们想要一些东西能够适用于这些短暂的系列。

所以我们，嗯，让我想想，就像去年九月，我们开始创建一个东西，我们就叫它TSI，时间序列索引，因为我们厌倦了尝试在命名上有创意。这就是它的样子，对吧？新数据进来，我们有索引，这是时间序列元数据，也就是键本身，对吧？我们检查了内存索引。然后我们检查磁盘索引。我们已经有了吗？如果我们做了，我们什么都不需要做。我们不需要把它写到磁盘上。我们就继续，继续我们的事业。但如果我们没有它，那我们就需要把它写进一个rightahead日志，就在一个只能用笔写的文件里？然后周期性地把这个wall写到内存索引中，然后周期性地把这个wall刷新到磁盘中。这和TSM非常相似，和我们的其他引擎非常相似。然后后台运行同情程序将这些索引文件合并成越来越大的索引文件？同样，就像TSM一样。这就是日志条目的样子。在我们的右航日志中，我们有一面旗帜。之所以有一个标志，是因为您可以删除或插入新的系列元数据。你有一个测量名称，标签，键，值，对和一个校验和。索引文件是这样的。我们有很多不同的块，我们屏蔽了索引中存在的序列，存在的标签，攻击，键值对，然后是存在的度量，然后是所有的集合不同位置的街区。我们来看看级数块是什么样的。嗯？我们有了这些不同的成分，对吧？我们有不同的级数键，然后我们有一个索引，然后我们有一堆更重要的键，然后是另一个索引。呃？还有一些其他的东西。现在，我们之所以有序列键，然后是索引，然后是更多的序列键，然后是索引，是因为我们不想，我们不想一次读取内存中所有的序列键。因此，由于错误，我们一次要写出65000个系列键，而且这些键的顺序总是很乱。这意味着，当我们遍历和压缩索引文件时，我们可以把它当作流作业来做，对吧？我们可以读取多个索引文件，把它们合并在一起然后写出65k级数，等等，等等，对吧？所以我们不需要在内存中有超过65000个序列键来把它放到磁盘上。好，我们来看看这个哈希索引。哈希索引的意义是，如果我们有一个重要的键，我们把它哈希到一个桶，对吧？假设这是我们的哈希表，我们有位置0，1，2，3，这些位置上的是文件字节偏移量的位置，对吧？假设我们有这个序列键，我们用你喜欢的哈希算法对它进行哈希，我们说它映射到bucket1。我们看到这是在02:34。所以我们跳到文件中的那个点，然后我们说，好的，这是严肃键的长度。然后我们可以看看键是否相同。那就需要查一下，比如，我们在这个文件里有这个吗？对吧？呃。所以我们使用的技术，这个，这个真的很有趣。直到去年秋天或夏天，我才听说过这种技术。这叫做罗宾汉哈希。它已经存在一段时间了，但它有一些优势非常非常适合我们的用例。您可以完全加载一个表。你不必这么做。通常是哈希表，对吧？就像你，你不想有额外的空间，所以你不会有很多冲突，因为如果你有哈希冲突，那么查找就会变得更昂贵，对吧？所以我们不需要为查找保存链接表。用罗宾汉哈希法，如果你在做只读哈希，就像我说的，TSI文件是不可变的。我们写一次，然后被读很多次。所以一旦我们计算了这个哈希索引，我们就不用再写了。所以我们不必担心更新或插入。我们不必担心删除，这意味着计算它的成本是随着时间平摊的。所以我要跳过，看看罗宾汉哈希，试着解释一下，希望你们能理解。最上面是哈希表的位置。中间部分是键，我们要查找的键。最后一个是我们所说的探测器，这一切都解释了。现在，对于这个例子，我将使用单个字符键，这样它就能很好地适应幻灯片，一切看起来都很好。首先，我们要把A插入哈希表。我们做哈希，A的位置是0。我们看，这里什么都没有，所以我们把A写在这里。好，现在我们要做B-B哈希是位置1。幸运的是，这里什么都没有，所以我们把B放在这里。呃。现在我们要把seasea哈希值插入到第一个位置，我们看，蜜蜂已经在那里了。接下来我们要做的，因为我们，因为我们不能把它放在这里，我们实际上看一下b的探测长度，我们看到它是零。但此时探针长度为零。所以探测长度就是你在哈希表上找到那个元素，找到那个键所需要的跳数。因为它们都是一样的，我们说，我们要跳到下一个位置，查找它，因为那里什么都没有，我们把sea放在那里，我们把它标记为探针长度为1，这样我们以后就可以记下来了。现在，在我们计算完并把它写到磁盘上之后，我们将扔掉这个问题数组。但是我们在构造哈希表的时候需要它。好吗？所以下一个是，我们要试着把哈希值插入到位置1。我们说，哦，不，我们不能这样做，因为a已经在那里了。所以我们移动到下一个位置。蜜蜂已经在那里了。但是在这一点上我们已经知道D的前长是1B的前长是1为零。所以我们把B踢出一个位置，把D放在那里，我们把这个市场空白，然后我们看看能否把它插入下一个位置。不。这是完整的。看这里，但是C的前长度也是1，所以我们只需要到下一个点去找D点。它是可用的。我们看到它在那里，所以我们把它放在那里，我们把探针的长度标记为2。所以这种移动的东西。这就是为什么它被命名为罗宾汉哈希。你从富有的探员那里抢劫，而你给贫穷的探员施舍，对吗？在这里，prorich尽可能接近于零，这是违反直觉的。所以另一个，基本上你在这里看到的是，当你对它进行查找时，你跳到下一个位置。所以你可以对查找做一个改进。当你写这个哈希表时，你需要写，表本身，也就是那个键表。在我们的例子中，我们在文件中存储了查找键的位置。但是你需要存储它，然后你需要存储最大探测长度。其他的都可以扔掉。但是你可以做的另一件事是你可以观察平均探针长度并存储它。在我们的例子中，我们会说，忽略位置假设它不在那里。我们就说平均长度是1。这就意味着，当我们以后查表的时候，我们做哈希来找到它的位置，然后加上平均值。在这种情况下，D的哈希值为0，我们给它加1，我们最终在第一次命中找到了确切的东西，而不需要移动探针。本质上，你最后要做的是，如果你查一下，把它加起来就得到了质谱，你在左右两边来回移动探针直到你到达一个位置，你要么得到了质谱。或者你找到了元素。这是现金ms。的样子。假设我们要查找Z，看它是否存在于文件中。Z哈希趋近于0，我们看到，好吧，A不是Z，如果不是，那么我们移动探针，我们说，D不是Z，所以不是它。注意到我们在跟踪Z的原长度，所以我们再次移动探针，C不是Z，我们现在也在原长度上。在这一点上我们知道我们可以退出，因为我们存储了最大探测长度。我们知道表中没有长度大于2的，所以我们知道它是现金。女士:啊，好的。最后一部分我想讲的是基数估计。所以我们估计，估计索引文件中有多少唯一序列的基数，有多少测量值，给定标签键有多少值，这是我们内部遥测的有用数据。我们稍后会在查询语言中添加一些东西来公开这些信息来做各种各样的事情。所以我们保留草图。基本上，我们使用超对数加加，这基本上是对旧的HLL算法的一些改进，但在这次演讲中不会涉及这些，但我们会有更多的细节，更详细的内容即将到来。呃？它在一个人的夜间构建中，而不是现在的三个。这是一个你可以打开索引的特性，你可以在配置中用一个标志打开这个特性。我几周前写了一篇博文，所以列在这里。它会告诉你怎么做。这就是我的演讲。谢谢你！谢谢你，保罗。现在我们要提问了。