# 🥇数据类型

## 🥈字符串（String）

**set**设置值

```shell
# ex：为key设置秒级的过期时间（同 expire 命令效果一样）
# px：为key设置毫秒级的过期时间
# nx：key不存在才可以设置成功，用于添加（分布式锁常用）
# xx：与nx相反，键必须存在才可以设置成功，用于更新
# PS：设置了过期时间的key，如果调用set修改它，过期时间会消失
set key value [ex] [px] [nx] [xx]

setex key seconds value # 同参数ex的作用一样
setnx key value # 同参数nx的作用一样
```

**get**获取值；键不存在返回空

**mset/mget**批量；批量操作命令可以有效提高效率，减少 RTT 的耗时

**getset**设置并返回原值

**incr**整数自增1；key不存在按0自增返回1；不是整数返回错误
类似命令还有：decr（自减）、incrby（自增指定步长）、decrby、incrbyfloat

**append**追加；可以向字符串尾部追加值

**strlen**返回字符串长度；注意：每个中文占3个字节

**setrange**设置指定位置的字符；下标从0开始计算

<img src="D:\ImageA\image-20231020111835871.png" alt="image-20231020111835871" style="zoom: 58%;" />

**getrange**截取字符串；需要指明开始和结束的偏移量，截取的范围是个闭区间

**命令的时间复杂度**
del、mset、mget 支持多个键的批量操作，时间复杂度和键的个数相关，为O(n)
getrange 和字符串长度相关，也是O(n)
其余命令都是 O(1) ，在速度上还是非常快的

**使用场景**缓存、计数器、共享session

## 🥈哈希（Hash）

**hset**设值；`hset user:1 name lijin`成功返回1反之返回0
**hsetnx**类似 setnx，只不过作用域由键变为 field
**hget**取值；`hget user:1 name`如果键或 field 不存在会返回nil
**hmset/hmget**批量

**hdel**删除一个或多个 field，返回成功删除的 field 个数

**hlen**计算field个数

**hexists**判断field是否存在1是0否

**hkeys**获取指定key所有field
**hvals**获取指定key所有value
**hgetall**获取指定key所有field与value
如果哈希元素个数比较多，会存在阻塞 Redis 的可能
如果只需要获取部分 field，可以使用 hmget
如果一定要获取全部 field-value，可以使用 hscan 命令渐进式遍历哈希类型

**hincrby/hincrbyfloat**自增；类似 incrby 和 incrbyfloat，只不过作用域是filed

**hstrlen**计算value的字符串长度

**命令的时间复杂度**

hdel、hmget、hmset 的时间复杂度和命令所带的 field 的个数相关，O(n)
hkeys、hgetall、hvals 和存储的 field 的总数相关，O(N)
其余的命令时间复杂度都是O(1)

**使用场景**

哈希类型比较适宜存放对象类型的数据，比字符串类型消耗内存更低

## 🥈列表（list）

- 列表类型用来存储多个有序的字符串（允许重复）
- 可以对列表两端插入和弹出，还可以获取指定范围的元素列表、获取指定索引下标的元素等
- 列表是一种比较灵活的数据结构，它可以充当栈和队列，在实际开发上有很多应用场景

**lrange**获取指定范围内的元素列表，不会删除元素；索引下标从左到右为0到N；`lrange 0 -1`命令可以从左到右获取列表的所有元素

**rpush/lpush**向右/向左插入；返回结果为插入后列表的长度即元素个数；支持同时插入多个元素

**linsert**在某个元素前/后插入新元素；返回结果为插入后列表长度即元素个数

**lpop/rpop**从列表左侧/右侧弹出，会删除元素

**blpop/brpop**阻塞式弹出元素，lpop/rpop 的阻塞版本，没有元素就会阻塞
支持设定阻塞时间/秒0表示一直阻塞
注意：brpop 后面如果是多个键，会从左至右遍历键，一旦有一个键能弹出元素，客户端立即返回

**lrem**删除等于 value 的元素，返回值是实际删除元素的个数
count>0：从左到右删除最多count个元素
count<0：从右到左删除最多count绝对值个元素
count=0：删除所有

**ltirm**按照索引范围修剪列表；例如想保留列表中第0个到第1个元素其他都删除

**lset**修改指定位置的元素
**lindex**获取指定位置的元素

**llen**获取列表长度

**使用场景**

- 消息队列：lpush+brpop 实现阻塞队列，生产者使用 lpush 从列表左侧插入元素，多个消费者使用 brpop 阻塞式消费
- 文章列表：每个用户有自己的文章列表，现需要分页展示，此时可以使用列表，因为列表不但有序，同时支持按照索引范围获取元素（分页）
- 实现其他数据结构
  - lpush+lpop = 栈
  - lpush+rpop = 队列
  - lpush+brpop=消息队列

## 🥈集合（set）

- 集合类型也是用来保存多个字符串元素（不允许有重复元素）（无序）（不能通过索引下标获取元素）
- 一个集合最多可以存储2的32次方-1个元素
- 支持集合内的增删改查、交集、并集、差集

**sadd**添加一个或多个元素；返回结果为添加成功的元素个数
**srem**删除一个或多个元素；返回结果为成功删除元素个数

**scard**计算元素个数

**sismember**判断元素是否在集合中1是0否

**srandmember**随机返回指定个数元素，默认是1个
**spop**随机弹出元素，会删除元素
**smembers**获取所有元素，不会弹出元素，返回结果是无序的

**sinter/suinon/sdiff**交集/并集/差集

**sinterstore/suionstore/sdiffstore**将计算结果保存

<img src="D:\ImageA\image-20231020110627422.png" alt="image-20231020110627422" style="zoom:70%;" />

**使用场景**标签、给用户贴标签、抽奖活动、随机数

## 🥈有序集合（ZSET）

<img src="D:\ImageA\image-20231020110728670.png" alt="image-20231020110728670" style="zoom:67%;" />

有序集合保留了集合不能有重复成员的特性，但可以使用分数排序（分数可以重复）

**zadd**添加成员，返回结果代表成功添加成员的个数

<img src="D:\ImageA\image-20231020110738561.png" alt="image-20231020110738561" style="zoom: 60%;" />

> nx: member必须不存在，才可以设置成功，用于添加
> xx: member必须存在，才可以设置成功，用于更新
> ch: 返回此次操作后，有序集合元素和分数发生变化的个数
> incr: 对score做增加，相当于后面介绍的 zincrby

**zcard**计算成员个数

**zscore**计算某个成员的分数，如果成员不存在则返回nil

<img src="D:\ImageA\image-20231020110753417.png" alt="image-20231020110753417" style="zoom:60%;" />

**zrank**计算成员的排名；分数从低到高，zrevrank反之

<img src="D:\ImageA\image-20231020110827053.png" alt="image-20231020110827053" style="zoom:60%;" />

**zrem**删除一个或多个成员，返回删除成功的个数

**zincrby**增加成员的分数

<img src="D:\ImageA\image-20231020110838563.png" alt="image-20231020110838563" style="zoom:60%;" />

**zrange/zrevrange**返回指定排名范围的成员；如果加上 withscores 选项，同时会返回成员的分数

<img src="D:\ImageA\image-20231020110854755.png" alt="image-20231020110854755" style="zoom:60%;" />

<img src="D:\ImageA\image-20231020110904117.png" alt="image-20231020110904117" style="zoom:60%;" />

**zrangebyscore**返回指定分数范围的成员
`zrangebyscore key min max [withscores] [limit offset count]`
`zrevrangebyscore key max min [withscores] [limit offset count]`

**zcount**返回指定分数范围成员个数`zcount key min max`

**zremrangebyrank**按升序删除指定排名内的元素`zremrangebyrank key start end`

**zremrangebyscore**删除指定分数范围的成员`zremrangebyscore key min max`

**zinterstore/zunionstore**交集/并集

> destination：交集计算结果保存到这个键
> numkeys：需要做交集计算键的个数
> key [key ...]：需要做交集计算的键
> weights weight [weight ...]：每个键的权重
> aggregate sum/min/max：计算交集后做分值汇总，默认是sum

不太好理解，我们用一个例子来说明（算平均分）

<img src="D:\ImageA\image-20231020110920311.png" alt="image-20231020110920311" style="zoom:58%;" />

<img src="D:\ImageA\image-20231020110930234.png" alt="image-20231020110930234" style="zoom:68%;" />

**使用场景**

排行榜系统；例如视频网站需要对用户上传的视频做排行榜，榜单维度可能是多个方面的：按照时间、按照播放数量、按照获得的点赞数量

# 🥇持久化

## 🥈RDB

RDB 是将某一时刻内存中的数据生成快照存储到硬盘（全量备份）

**是否阻塞主线程？**

- save：在主线程中执行，将导致阻塞
- bgsave：创建一个子线程，用来备份数据（将内存复制一份用于子进程的备份）
- 除了上面两种手动触发备份的方式，还可以通过配置自动触发备份，如下图
  <img src="D:\ImageA\image-20230331184742732.png" alt="image-20230331184742732" style="zoom: 80%;" />

执行 shutdown 命令时如果没有开启 AOF 将触发 bgsave

时点性：假如1点开始备份数据，1点以后的数据不会被备份

子进程将数据写入临时 RDB 文件中，完成写入时用临时 RDB 替换掉旧的 RDB

优点：1、数据恢复速度快；2、全量数据，可用于灾难恢复
缺点：做不到实时持久化

## 🥈AOF

> append only file

记录每次写操作的日志，默认不开启

先写缓冲区，择时同步磁盘

- always：每个写命令执行完，立马同步地将日志写回磁盘（对性能影响太大，不建议配置）
- everysec：每个写命令执行完，先把日志写入内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘（默认配置，理论上只有在系统突然宕机的情况下丢失1秒的数据）
- no：每个写命令执行完，先把日志写入内存缓冲区，由操作系统决定何时写磁盘，通常是30秒（写磁盘周期不可控，虽然提升了性能，但数据安全性无法保证）

命令不断写入 AOF 越来越大，为了解决这个问题，重写机制压缩 AOF 的体积，同时还能加快数据恢复速度

优点：丢失数据少
缺点：数据恢复速度没有RDB快

同 RDB 一样都是子进程异步备份

**重写机制**

随着命令不断写入 AOF，文件会越来越大，为了解决这个问题，Redis 引入 AOF 重写机制压缩文件体积

文件重写是把 Redis 进程内的数据转化为写命令同步到新 AOF 文件

文件变小的原因：
1、最终数据去掉了无效命令，因此文件变小
2、多条写命令可以合并为一个

**重写过程触发**

手动触发：直接调用 bgrewriteaof 命令

自动触发：根据`auto-aof-rewrite-min-size`和`auto-aof-rewrite-percentage`参数确定触发时机
`auto-aof-rewrite-min-size`表示运行 AOF 重写时文件的最小体积，默认为64MB
`auto-aof-rewrite-percentage`代表当前 AOF 文件空间和上一次重写后 AOF 文件空间的比值

AOF 重写时，如果有写入操作，这个操作会被写到重写日志的缓冲区保证数据不会丢失

**重启加载**

1、当AOF和RDB文件同时存在时，优先加载AOF；若关闭了AOF，加载RDB文件
2、加载 AOF/RDB 成功，Redis重启成功
3、AOF/RDB 存在错误，启动失败打印错误信息

## 🥈RDB-AOF混合持久化

通过`aof-use-rdb-preamble`配置项可以打开混合开关，默认是禁用的

该状态开启后，如果执行 bgrewriteaof 命令，会把当前内存中已有的数据弄成二进制存放在 AOF 文件中（即RDB）
后面有其他命令，在触发下次重写之前，依然采用 AOF 追加的方式

## 🥈为什么主从复制不用AOF

1、RDB 是二进制文件，无论是写入磁盘，还是通过网络传输，IO效率 AOF 的高
2、在从库进行恢复时，RDB 的恢复效率更高

# 🥇缓存穿透、击穿、雪崩

`锚点#缓存穿透、击穿、雪崩`

**穿透**查询一个根本不存在的数据，缓存和数据库中都没有数据，穿透了

解决方案1：缓存一个空数据，避免下一次访问数据库

解决方案2：使用布隆过滤器过滤无效请求
如何解决布隆过滤器的 hash 碰撞？
1、增大数组，减小误差率
2、增加 hash 函数

**击穿**场景：缓存中无数据，数据库有数据

举例说明：一个 key 失效后，读数据直接读数据库，并发量特别大的时候就造成击穿

~~数据阈值式清理~~绝大部分情况下只有热点 key 才会并发量特别大
因此使用 LRU 或 LFU 算法保证热点 key 不失效即可，非热点 key 失效了也没关系

~~过期式清理~~加互斥锁，伪代码如下图（而且互斥锁方案还可以为数据阈值式清理兜底）
<img src="D:\ImageA\image-20230331191804005.png" alt="image-20230331191804005" style="zoom: 67%;" />

**雪崩**大量缓存同时失效，数据库压力暴增，即为雪崩

场景1：Redis自身失效
场景2：同一时间大量缓存过期

解决方案：
1、保证缓存服务的高可用，做到即使个别节点宕机依然可以提供服务；哨兵和集群都能做到
2、将缓存失效的时间分散开，在固定时间基础上加一个随机时间

# 🥇双写一致性

参考`锚点#双写一致性`

# 🥇缓存清理机制

## 🥈数据阈值式清理

`锚点#数据阈值式清理`

**maxmemory**Redis 提供了配置参数 maxmemory 来限制内存超出期望大小，当实际内存超出 maxmemory 时，可选的淘汰策略如下：

**Noeviction**默认的淘汰策略，不会继续服务写请求（DEL可以），读请求可以继续进行

**volatile-lru**只淘汰设置了过期时间的key；淘汰算法是LRU，最少使用的 key 优先被淘汰
**volatile-lfu**同上；淘汰算法是LFU
**volatile-ttl**跟上面一样；淘汰策略TTL：ttl 越小越优先被淘汰
**volatile-random**跟上面一样，随机淘汰

**allkeys-lru**区别于 volatile-lru，这个策略要淘汰的是全体的 key，没有设置过期时间的 key 也会被淘汰；淘汰算法是LRU
**allkeys-lfu**同上；淘汰算法是LFU
**allkeys-random**同上，随机淘汰

推荐使用 LRU 或 LFU 算法，避免热点 key 被淘汰，可以提高缓存命中率

### 🥉LRU算法

实现 LRU 算法除了需要 KV 字典外，还需要附加一个链表
当空间满的时候，会踢掉链表尾部的元素
当字典的某个元素被访问时，它在链表中的位置会被移动到表头

### 🥉近似LRU算法

Redis 使用一种近似 LRU 算法，之所以不使用 LRU，是因为需要消耗大量额外内存，需要对现有数据结构进行较大改造

- 近似 LRU 算法给每个 key 增加了一个24位的时钟字段，存储最后一次被访问的时间戳
  Redis 维护了一个24位的全局时钟，可以简单理解为当前系统的时间戳，每隔一定时间会更新这个时钟
- 当新增 key 对象的时候会把全局时钟赋值到这个 key 对象的时间戳字段
- 执行淘汰策略的时候，随机采样出 5个key（可配置），然后找到内部时间戳与全局时钟距离时间最久（差最大）的 key 进行淘汰，之后如果内存还是超出 maxmemory，继续随机采样淘汰

### 🥉LFU算法

它的核心思想是根据 key 的最近被访问的频率进行淘汰，很少被访问的优先被淘汰

LFU 算法能更好的保留热点数据

原理：使用计数器来对 key 进行排序，每次 key 被访问的时候计数器增大，计数器相等的 key 按照时间排序

LFU 把 key 对象的内部时钟的24位作为“热度”分成两部分

- 前16位还代表时钟，存储上一次计数器更新的时间，16位精度不可能很高，它取的是分钟时间戳对2的16次方进行取模
  平时不更新，进行缓存淘汰时才更新
- 后8位是一个计数器存储访问频次（8位最大表示整数255，不够用，所以它存储的是频次的对数，并且这个值还随着时间衰减）

每次淘汰都是采用随机策略，随机挑选若干 key，更新这个 key 的“热度”，淘汰掉“热度”最低的 key

## 🥈过期式清理

`锚点#过期式清理`

**定时扫描策略**

Redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，定时扫描这个字典来删除到期的 key
默认每秒进行十次过期扫描，过期扫描不会遍历字典中所有的 key，而是随机策略
1、从字典中随机 20 个 key，删除这 20 个 key 中已经过期的 key
2、如果过期的 key 比率超过 1/4，就重复步骤 1

此时存在一个问题，如果大量的 key 同一时间过期了，这个循环会执行多次，这就会导致读写请求明显卡顿
所以开发者要注意过期时间，如果有大批量的 key 过期，要给过期时间设置一个随机范围，而不能全部在同一时间过期

从库的过期策略？没有策略；主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库

**惰性删除**

除了定时扫描之外，Redis 还会使用惰性策略来删除过期的 key，即客户端访问这个 key 的时候，如果过期了就立即删除

**lazyfree**

使用 DEL 命令删除体积较大的键， 或者在使用 FLUSHDB 和 FLUSHALL 删除包含大量键的数据库时，会造成 Redis 阻塞

另外 Redis 在清理过期数据和淘汰内存超限的数据时，如果碰巧撞到了大体积的键也会造成服务器阻塞

为了解决以上问题，~~Redis4.0~~引入了 lazyfree 的机制，删除对象时只是异步逻辑删除，后台线程执行真正的删除

# **

# 与memcached的区别

1、memcached 不具备持久化能力，redis 具备
2、redis 支持丰富的数据类型，memcached 只支持字符串
3、redis 支持在数据上计算
4、redis 还有其他 memcached 不具备的特性：Lua脚本、发布订阅、主从高可用
5、网络IO模型：redis是单线程的，memcached是多线程的
6、redis 原生支持分片集群，memcached 不支持

# 为什么要使用Redis

参考下一个问题：Redis合适的应用场景

# Redis合适的应用场景

考察对各种数据结构的理解，去上文的数据类型中找答案

# 为什么使用Pipeline

Redis 客户端执行一条命令分为如下4个部分：

1. 发送命令
2. 命令排队
3. 命令执行
4. 返回结果

其中1和4花费的时间称为 Round Trip Time（往返时间 RTT），即数据在网络上传输的时间

Redis 命令真正执行的时间通常在微秒级别，RTT 很可能要比这个时间大很多倍（根据光纤速度计算）

Pipeline 机制能改善上面这类问题，它能将一组命令进行组装，仅仅通过**一次RTT**传输给 Redis，再将这组命令的执行结果按顺序返回给客户端
不使用 Pipeline 的话整个过程需要**n次RTT**

我测试过10000次字符串数据类型的 set 写入，使用 pipeline 耗时10毫秒，不使用的话耗时1000毫秒，差距100倍

PS：Pipeline 虽然好用，但每次组装的命令个数也不能没有节制，因为数据量过大的话可能会长时间阻塞 Redis 的主线程，可以将一次包含大量命令的 Pipeline 拆分成多次较小的 Pipeline 来完成

# 为什么Redis单线程也这么快

**C语言实现，效率高**C语言程序运行时要比其他语言编写的程序快得多，因为它离底层机器很近

**纯内存访问**访问内存速度要比访问磁盘快得多

**单线程的优势**单线程能够避免上下文切换

**Pipeline**参考上面的问题：为什么使用Pipeline

**渐进式rehash**hash冲突过多的情况下，扩容采用渐进式rehash TODO

**基于epoll的多路复用NIO**
一般的IO操作是阻塞的，如果命令没有返回长时间阻塞就无法执行其他命令
epoll NIO 解决了IO操作阻塞的问题，如果命令没有返回可以继续执行其他命令

**lazyfree**参考上文的 lazyfree

# Redis真的是单线程吗

命令的执行和返回结果是由主线程串行执行的，但严格来说 Redis 并不是单线程

Redis 还有一些后台线程执行操作，例如清理脏数据、无用连接的释放、持久化

# Redis6.0之前为什么不使用多线程

官方曾做过类似问题的回复：Redis 几乎不存在 CPU 成为瓶颈的情况，主要受限于内存和网络
对于绝大多数企业来说，单线程性能足够了，因此没有必要使用多线程

# Redis6.0为什么要引入多线程

对于绝大多数企业来说，单线程性能足够了（8-10W的QPS），但是巨头公司需要更大的 QPS

使用多线程可以分摊 Redis 同步 IO 读写负荷

Redis 作者在一个分享中曾提到：Redis6 引入的多线程 IO 特性对性能提升至少是一倍以上
国内也有人进行过测试，GET/SET 命令在4线程 IO 时性能相比单线程是几乎翻倍
如果开启多线程，至少要4核的机器

# 什么情况下可能导致Redis阻塞

1、参考上文的 lazyfree
2、`keys *`数据量大的话阻塞
3、AOF同步写
4、持久化fork子进程（fork会复制父进程的空间内存页表，耗时跟内存量成正比，建议内存控制在10GB以内）