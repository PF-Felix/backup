# 基础

## 范式

第一范式：列不可再分
反例1：有一列为班级，一条数据为计算机系3班，这就违背了不可再分原则，因为可以再分为系别、班级
反例2：JSON存储一个对象

第二范式：首先必须满足第一范式，且任何非主键列完全依赖于主键，而不是局部依赖于某个主属性
反例：学生成绩表（学号，学科，姓名，分数）学号+学科是主键，但是姓名只依赖于学号

第三范式：首先必须满足第二范式，且不能存在传递依赖，即非主属性与主键应是直接关系而不是间接关系
反例：学生（学号，姓名，系名，系主任）主键是学号，系主任与系名是直接关系 与学号是间接关系

范式：减少数据冗余、更新快
反范式：减少表的关联
工作中没有必要严格遵守范式
应该根据实际情况，范式+反范式结合，适当的允许冗余字段，以空间换时间

## 字段数据类型的优化

### 基本原则

**更小的通常更好**：更小的数据类型通常更快
**简单就好**：简单数据类型的操作通常需要更少的CPU周期；比如整型比字符操作代价更低，比如应该使用日期类型而不是字符串来存储日期和时间

### 整数类型

类型：TINYINT、SMALLINT、MEDIUMINT、INT、BIGINT
存储空间：8、16、24、32、64位，即1、2、3、4、8个字节
UNSIGNED 类型的整数类型不允许负值，可以使正数的上限提高一倍
有符号和无符号类型使用相同的存储空间，并具有相同的性能
integer 和 int 没有任何差别
长度（宽度）与存储空间无关，与可视化客户端的显示的字符个数有关

### 小数类型

MySQL 有精确类型 DECIMAL、不精确类型（浮点类型）FLOAT 和 DOUBLE
作为替代方案，可以考虑使用 BIGINT 代替 DECIMAL，相当于扩大了 N 倍

### 字符串类型

==CHAR==
定长字符串，检索和写效率高

==VARCHAR==
可变长字符串，比定长类型更省空间，因为它仅使用必要的空间
但是，如果一个行占用的空间增长，并且页内没有空间可以存储，就需要页分裂移动数据，影响写效率

==BLOB，TEXT==
都是为存储很大的数据而设计的字符串数据类型
BLOB：二进制存储、没有排序规则或字符集
TEXT：字符方式存储，有排序规则和字符集
最好避免使用，因为可能引起一些性能问题；如果一定要使用，一般把这个列分离到单独的表中

### 日期和时间类型

TIMESTAMP 范围：1970年~2038年，并且跟时区有关
DATETIME 范围：1001年~9999年，推荐
MySQL 最小时间粒度为秒，如果需要存储粒度更小的时间值怎么办？可以使用 BIGINT 类型存储微秒级别的时间截

# 事务

## 事务的四个特性
> ACID

- 原子性：事务中的操作要么全部成功，要么全部失败；==MySQL 通过 UndoLog 实现==
- 一致性：数据库在事务执行前后都处于一个正确的状态，数据完整性没有被破坏；==通过其他三个特性来保证==
- 隔离性：事务执行过程中，不应该收到其他事务的打扰，并发的事务要隔离；==事务并发带来脏读、不可重复读、幻读；MySQL 通过 MVCC+锁 解决==
- 持久性：事务执行完成之后，数据将永远保存在数据库中，即使出现意外宕机的情况，也不应该对这部分数据造成任何影响；==MySQL 通过 RedoLog 实现==

### 脏读&不可重复读&幻读
脏读：在一个事务中读取到另⼀个事务未提交的数据
![image-20230317014322915](C:\backup\assets\image-20230317014322915.png)

不可重复读：事务内相同的记录被检索两次，但两次得到的结果不同（强调数据的更新和删除）
![image-20230317014340713](C:\backup\assets\image-20230317014340713.png)

幻读：事务内相同的记录被检索两次，但后面一次得到的结果有新数据加入（强调数据的新增）
![image-20230317014352123](C:\backup\assets\image-20230317014352123.png)
## 事务的四个隔离级别

SQL标准中的隔离级别：
![image-20230317014053959](C:\backup\assets\image-20230317014053959.png)

MySQL中的隔离级别：
![image-20230317014127685](C:\backup\assets\image-20230317014127685.png)

MySQL 默认的隔离级别是可重复读
在可重复读隔离级别下，MySQL 没有完全解决幻读的问题，但提供了解决幻读的支持，如果应用程序事务处理的好是可以解决幻读问题的
可串行化是万万不能选择的，不支持并发性能太低

## MVCC
> 多版本并发控制

为了提高数据库并发性能，用更好的方式去处理读写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读
MVCC 基于版本链和 ReadView 实现

### 版本链
> 每个版本链针对的是一条数据

MySQL 聚簇索引中有三个隐藏字段（每行数据中都有）
- `DB_TRX_ID`：最后一次修改这条数据的事务ID
- `DB_ROLL_PTR`：每次对某条聚簇索引的记录修改，都把旧版本写入 UndoLog，这个隐藏字段相当于一个指针，指向 UndoLog 中上一个数据版本
- `DB_ROW_ID`：隐藏的主键，如果数据表没有主键，自动生成一个6字节的 row_id

![image-20230317014154050](C:\backup\assets\image-20230317014154050.png)

不同事务对同一记录的修改，导致此记录的 UndoLog 形成一个版本链，下面图片实例模拟版本链的生成

![image-20230317014217953](C:\backup\assets\image-20230317014217953.png)

![image-20230317014206999](C:\backup\assets\image-20230317014206999.png)

![image-20230317014250397](C:\backup\assets\image-20230317014250397.png)

对于使用未提交读隔离级别的事务，由于可以读到未提交事务修改过的记录，所以直接读取记录的最新版本就好了（不需要MVCC）
对于使用可串行化隔离级别的事务，加锁解决（不需要MVCC)

### ReadView
Read View 用来做可见性判断的，作用于快照读，有三个全局属性：
- `trx_list`：记录 Read View 生成时活跃的事务ID列表
- `up_limit_id`：记录 trx_list 列表中最小值
- `low_limit_id`：记录 Read View 生成尚未分配的下一个事务ID（PS：事务ID递增分配）

遍历版本链的比较规则（关键的是第三个判断）：

1. 判断`DB_TRX_ID < up_limit_id`
   1. 是：当前事务能看到 DB_TRX_ID 所在的记录
   2. 否：进入下一个判断
2. 判断`DB_TRX_ID >= low_limit_id`
   1. 是：代表 DB_TRX_ID 所在的记录在 Read View  生成后才出现的，对于当前事务肯定不可见，继续遍历
   2. 否：进入下一步判断
3. 判断`DB_TRX_ID in trx_list`
   1. 是：当前事务不应该看到活跃事务的修改，继续遍历
   2. 否：说明这个历史记录对当前事务可见
### RC解决脏读
> RC：READ COMMITTED 读已提交

**读已提交隔离级别的事务，每个快照读都生成一个 ReadView**
如果进入第三个判断，如果这个记录被活跃事务修改了，当前事务是不可见的，继续遍历；这种机制下就避免了脏读问题
但有不可重复读问题，因为已经提交的事务不再是活跃事务，它的修改记录对当前事务可见

### RR解决不可重复读
RR 隔离级别的事务，**只有首次快照读生成 ReadView**，之后的快照读将重复利用这个 ReadView
这样的话，其他事务提交之后还是被当作了活跃事务处理，其修改对当前事务是不可见的，因此解决了不可重复读问题

### RR解决幻读问题
快照读：如果一直使用快照读，不可能读到其他事务新增的数据，自行分析
当前读：如果第一次是快照读，第二次是当前读，可能发生幻读，因为当前读没有利用MVCC

总结一下就是：
- 如果事务中都是快照读，不可能产生幻读
- **快照读和当前读一起使用时可能产生幻读，应该避免**
- 如果事务中都是当前读，通过临键锁来解决幻读问题
## RedoLog
数据是存放在磁盘中的，如果每次读写数据都需做磁盘IO操作，并发场景下性能就会很差，为此 Mysql 引入缓存 BufferPool 来缓解数据库的磁盘压力

- 当从数据库读数据时，首先从缓存中读取，如果缓存中没有，则从磁盘读取后放入缓存
- 当向数据库写入数据时，先向缓存写入，此时缓存中的数据页数据变更，这个数据页称为脏页
- BufferPool 中的数据会定期刷到磁盘中，这个过程称为刷脏页

数据库宕机，如果刷脏页还未完成，内存中的更新丢失就无法保证事务的持久化，为了解决这个问题引入了 RedoLog
RedoLog 是物理日志不是逻辑日志，记录的是数据库中每个页的修改，用来恢复事务提交后的物理数据页
写日志和写数据的顺序：先写日志，再修改 BufferPool 中的数据；如果顺序反过来，可能存在日志和数据不一致的情况

RedoLog 也是先在内存中缓存的，有个参数`innodb_flush_log_at_trx_commit`可以控制 RedoLog 刷盘时机
- 0：事务提交时不立即刷盘，这个任务是交给后台线程做的（可能造成数据的修改丢失）（每秒写入OS Buffer）
- 1：事务提交时立即刷盘，可以保证事务的持久性，是默认值（每次写入OS Buffer + 刷盘）
- 2：事务提交时将 RedoLog 写到操作系统缓冲区，不保证刷盘（每次写入OS Buffer）
## UndoLog
用来保证事务的原子性

此外 MVCC 的版本链就是 UndoLog

## 锁

> 标签：锁

### 共享锁(S)与排它锁(X)

共享锁允许其他事务读，不允许写
排它锁都不允许

S兼容S
S不兼容X
X不兼容X

### 行锁与表锁
InnoDB 的行锁是给索引项加锁；只有真正通过索引检索数据，InnoDB 才使用行锁，否则使用表锁
行锁分为记录锁、间隙锁、临键锁=记录锁+间隙锁
间隙锁和临键锁用于解决幻读问题

```shell
#记录锁
#等值查询，锁定单行记录

#间隙锁
#当查询的记录不存在，无论是用等值查询还是范围查询的时候，它使用的都是间隙锁，锁定记录间隙

#临键锁
#范围查询，不仅仅命中了记录，还包含了间隙，使用的就是临键锁，它是默认的行锁算法，相当于记录锁加上间隙锁
#select * from t2 where id >5 and id =7 for update; 锁住 (4,7] 和 (7,10]
#select * from t2 where id >8 and id =10 for update; 锁住 (7,10] 和 (10,+∞)
#Mysql8不再锁下个区间
```

![image-20230416230020978](C:\backup\assets\image-20230416230020978.png)

### 意向锁
意向锁是表锁，分为意向共享锁、意向排它锁，它们的提出仅仅为了在之后加表级别的共享锁和排它锁时可以快速判断表中是否有行锁，以避免用遍历的方式来查看表中有没有上锁的记录
## **

## 隐式提交
如果开启自动提交`autocommit=ON`，输入了某些语句之后就自动提交
如果关闭自动提交`autocommit=OFF`，或使用`START TRANSACTION`、`BEGIN`开启了一个事务，事务不进行自动提交

## 快照读、当前读
快照读：读取的不一定是最新记录，也有可能是某个历史记录；普通的查询是快照读，不加锁
当前读：读取的是最新记录，且对读取的记录加锁，保证其他并发事务不能修改当前记录；当前读的例子如下

- `select lock in share mode`共享锁
- `select for update`排它锁
- `update`排它锁
- `insert`排它锁
- `delete`排它锁

==update、insert、delete这些操作为什么是当前读？==
1、假设当前事务先快照读
    2、其他事务再新增提交
        3、当前事务再更新数据，如果更新操作快照读就更新不了已经被其他事务提交的记录

BinLog 中当前事务更新操作在其他事务提交之后，同步到 slave 中数据是不一致，slave 中更新了其他事务提交的记录
## 幻读可能带来什么问题
TODO
## BufferPool
BufferPool（缓存池）用来缓存表数据与索引数据，减少磁盘IO
缓存池中存储的是一个个缓存页（16K），每个缓存页都有一个控制块，采用链表来管理数据页

空闲的缓存页（Free Page）对应的控制块都存入一个链表中，称作==Free链表==
访问某页的数据时，缓存池中有的话直接读取；没有的话从磁盘读取此页加载到缓存池中，从 Free链表中取出一个空闲的缓存页加载，并将其对应的控制块移出链表

==如何判断缓存池中有没有某个页？==为已加载的缓存页建立一个哈希表，key为表空间号+页号，value为缓存页对应的控制块
当需要访问某个页的数据时，先从哈希表中根据表空间号+页号看看是否存在对应的缓冲页
如果有，则直接使用；如果没有，就从Free链表中选出一个空闲的缓存页，然后把磁盘中对应的页加载进来...

修改过的页（dirty page）的控制块存储存储在一个==Flush链表==中，在未来某个时间刷盘

缓存淘汰有一个==LRU链表==，新访问过缓存页的控制块调整到链首，缓存不够用的时候淘汰链尾的缓存页
但是数据库提供了预读，读入的某些缓存页可能一次都没有用过，都放入链首的话可能导致热点缓存页比这些无用的缓存页先淘汰，这将大大降低缓存命中率；解决办法就是将 LRU 链表分为两截 Young 和 Old，预读时先将缓存页的控制块存入 Old 区首部（Old 区空间不够时尾部的无用缓存页被淘汰），Old 区的缓存页被访问就会被当作热点数据移动到 Young 区的首部
![image-20230416101736756](C:\backup\assets\image-20230416101736756.png)

并发访问各种链表都需要加锁处理，因此拆分为多个小的缓冲池，提高并发能力（类似于 ConcurrentHashmap 的桶）

### 预读

磁盘读写，并不是按需读取，而是按页读取，如果未来要读取的数据就在页中，就能够省去后续的磁盘IO，提高效率

### ChangeBuffer

如果 DML 操作请求的==辅助索引（二级索引）==没有在缓存池中，并不会立刻将磁盘页加载到缓存池，而是在 ChangeBuffer 记录变更，等未来数据被读取时，再将数据合并恢复到 BufferPool 中

为什么只针对辅助索引呢？因为唯一索引在进行修改时必须要做唯一性校验，因此必须查询磁盘做一次IO操作，会直接将记录查询到 BufferPool 中，然后在缓存池修改，不会在 ChangeBuffer 操作

## BinLog
BinLog 记录的是所有修改操作，是逻辑日志，用来备份数据和主备同步数据

想要做到主备数据一致就得保证 RedoLog 和 BinLog 的一致性，因此 RedoLog 的写入使用两阶段提交【如下图】
prepare 阶段 RedoLog 写入磁盘，然后 BinLog 写入磁盘，最后事务提交

![image-20230317014411168](C:\backup\assets\image-20230317014411168.png)

> 上图有个错误点：应该是先写 redolog 再更新缓存

在 BC 两个点可能宕机出现数据不一致的问题，怎么解决？
重启后如果发现 RedoLog 处于 prepare 状态，就通过事务ID 检查 BinLog 是否包含此条 RedoLog 的内容，如果不包含 RedoLog 丢弃此次变更，如果包含事务将提交

# 索引

## B+树索引

### 聚簇索引

> 也叫聚集索引、主键索引

InnoDB用表的主键构造了一个B+树，整个表的行记录数据（数据页）存放在叶子节点中，这就是聚簇索引（数据绑定于索引）
MyISAM 索引文件和数据是分离的，叶子节点存储的是数据记录的地址，是非聚簇索引（主键索引和二级索引都是）

每个表只有一个聚簇索引
如果没有定义主键呢？数据库使用唯一索引，如果没有唯一索引，就使用一个隐含列 RowID 来做主键

主键和唯一索引的区别？
主键不能为空，唯一键可以
主键是给二级索引引用的
主键只有一个，唯一索引不限个数

### 辅助索引

> 也叫二级索引

在非主键列建立的索引是辅助索引，叶子节点存储的是主键的值
每个表可以有多个辅助索引
PS：MyISAM 辅助索引叶子节点存储的是数据记录的地址

### 联合索引

> 也叫复合索引

在多个字段上建立的一个索引称之为联合索引
联合索引是辅助索引

### 回表

当通过辅助索引来寻找数据时，数据库遍历辅助索引并通过叶子节点找到主键，然后再通过聚簇索引来找到一个完整的行记录，这个过程也被称为回表

为什么不直接把完整的用户记录放到辅助索引叶子节点呢？
1、浪费存储空间
2、数据变化更新所有索引性能低下

### 索引覆盖

不是索引
意思是从辅助索引中就可以得到查询的记录，不需要回表

## 哈希索引

B+树的查找次数取决于树的高度，需要多次IO查询

数据库监控经常用的索引，为其创建了一个哈希索引（速度优于B+树）称为自适应哈希索引；查询的时候如果能命中自适应哈希索引就不用再使用B+树索引

哈希索引只能用来搜索等值的查询

是否开启此特性`innodb_adaptive_hash_index`默认为开启状态

## 全文索引

## 高性能索引创建

### 索引列类型尽量小

> 类型表示的数据范围的大小

数据类型越小，在查询时比较操作越快
数据类型越小，索引占用的存储空间就越少，在一个数据页内就可以放下更多的记录，从而减少磁盘IO带来的性能损耗

### 选择离散性高的列

重复的数据少，能过滤掉更多的数据

### 前缀索引

针对很长的 varchar、blob、text 需建立前缀索引
```sql
Alter table tableName add key/index (column(X))
```
缺点：无法做 ORDER BY 和 GROUP BY

后缀索引：Mysql 不支持，但是可以把字符串反转后存储，并基于此建立前缀索引

### 为条件、排序、分组列创建索引

出现在查询列表中的列一般就没必要建立索引了，除非是需要使用索引覆盖

### 联合索引的列顺序至关重要

将离散性最高的列放到索引最前列
在优化性能的时候，可能需要使用相同的列但顺序不同的索引来满足不同类型的查询需求

### 三星索引

1、索引将相关的记录放到一起则获得一星（比重27%）（索引行相邻或足够靠近最好）
2、如果索引中的数据顺序和查找中的排列顺序一致则获得二星（排序星：比重27%）（不用再另外排序）
3、如果索引中的列包含了查询中需要的全部列则获得三星（宽索引星：比重50%）（索引覆盖避免回表）

## 高性能索引优化策略

### 不在索引列上做任何操作

做计算：`SELECT * FROM order_exp WHERE id + 1 = 17;`
用函数：`SELECT * from order_exp WHERE YEAR(insert_time)=YEAR(DATE_SUB(NOW(),INTERVAL 1 YEAR));`
上面的情况都无法利用索引，索引失效

### 字符串类型加引号&整型不要加引号

两种情况的反例都会触发隐式类型转换，会导致索引失效

### is null & is not null

大概率导致索引失效（不是一定但可能性很大）

### %开头的like

索引失效

### or需要注意

如果所有查询条件的列都有索引，那么可以使用索引合并来优化查询
如果只有部分列有索引，或者没有索引，那么不会使用索引

### 联合索引全值匹配&最左匹配原则

不是全值匹配的话也应该遵循最左匹配原则，必须匹配最左边的列

### 使用索引覆盖避免回表

无需回表

### 联合索引用后面列范围查询

使用前面索引列范围查询，后面索引列失效

### 不等于

使用不等于将无法使用索引导致全表扫描

### 按主键顺序插入记录

最简单的是自增主键，插入数据时，写入的目标页很可能是缓存中已有的页，顺序写入更快

UUID 这种插入记录时是乱序的
1、写入的目标页可能不在缓存中或者已经被淘汰，此时就需要大量随机IO
2、写入是乱序的，需要大量的移动数据

### 联合索引排序

对于使用联合索引排序，必须满足下面规则，否则索引排序失效
1、各个索引列排序规则必须一致，都是ASC or 都是DESC
2、索引列顺序和 order by 子句顺序完全一致

### 其他索引失效场景

优化器认为使用全表扫描要比使用索引快，则不使用索引

join 的两个表的字符编码不同，不能命中索引

## **

## B+树进化史

==为什么不用《哈希索引》==

- 只能定位单条数据，无法做到范围查询
- 数据量很大时，哈希冲突概率也会非常大
- 不支持利用索引排序

==树→二叉树→二叉查找树==

二叉查找树效率高，类似二分查找，二叉查找树符合以下几点：
1、左子树的所有的值小于根节点的值
2、右子树的所有的值大于或等于根节点的值

但是如果设计不好，可能形成一个不平衡的二叉查找树，树的深度太深影响查询效率

==平衡二叉树==

是一棵二叉查找树，左右两个子树的高度差不超过1，左右两个子树都是一棵平衡二叉树
维护一棵平衡二叉树的代价是非常大的

==B+树==

由二叉平衡树演化而来
是一颗多叉树，树的高度远低于平衡二叉树，减少了磁盘IO次数
只有叶子节点存储数据，叶子节点由小到大（物理无序、逻辑有序、指针相连）串联在一起，叶子页中的数据也是排好序的

![image-20230406192412064](C:\backup\assets\image-20230406192412064.png)

==为什么不用B树？==
B树每个节点都存储数据，相同数据规模下将增加磁盘IO次数，相比下来B+树磁盘IO次数少
B+树采取顺序读，B树是随机读
B+树能提高范围查询的效率，因为叶子节点指向下一个叶子节点

## 密集索引、稀疏索引

密集索引：叶子节点保存的不只是键值，还保存了位于同一行记录里的其他列的信息，一个表只能创建一个密集索引
稀疏索引：叶子节点仅保存了键位信息以及该行数据的地址

MyISAM 不管是主键索引、唯一键索引还是普通索引都是稀疏索引
InnoDB 有且只有一个密集索引即聚集索引，二级索引是稀疏索引

执行计划查看具体执行查询的方式
语法：`EXPLAIN select * from table1`

# 执行计划

执行计划查看具体执行查询的方式

语法：`EXPLAIN select * from table1`

## id

每个 SELECT 关键字都对应一个 id

单SELECT关键字就不说了

==连接查询==
多个 SELECT 关键字，在连接查询的执行计划中，每个表都对应一条记录，这些记录的 id 列的值是相同的
![image-20230406195139236](C:\backup\assets\image-20230406195139236.png)

==包含子查询==
多个 SELECT 关键字
特别的情况：查询优化器可能对涉及子查询的查询语句进行重写，转换为连接查询
下面例子是一个子查询，但是执行计划中两个表对应的记录的 id 值都是1，这表明查询优化器将子查询转换为了连接查询
![image-20230406195301217](C:\backup\assets\image-20230406195301217.png)

==包含UNION子句==
多个 SELECT 关键字
特别的情况：合并结果集的时候需要去重（id=NULL）
![image-20230406195354855](C:\backup\assets\image-20230406195354855.png)

==UNION ALL==
不需要去重
![image-20230406195421227](C:\backup\assets\image-20230406195421227.png)

## table

表名

## partitions

和分区表有关，一般情况下执行计划的 partitions 列的值都是 NULL

## type

访问类型，是较为重要的一个指标，出现比较多的是：`system > const > eq_ref > ref > range > index > ALL`（从好到坏）

### system

innodb 引擎没有这种情况出现

### const

根据主键或唯一二级索引与常数进行等值匹配时，对单表的访问类型就是 const，因为只匹配一行数据，所以很快
![image-20230406195509646](C:\backup\assets\image-20230406195509646.png)

如果主键或唯一二级索引是由多个列构成的话，组成索引的每一个列都是与常数进行等值比较时，这个 const 访问类型才有效

### eq_ref

在连接查询时，如果被驱动表是通过主键或唯一二级索引列等值匹配的方式进行访问的，则对该被驱动表的访问类型就是 eq_ref
如果主键或唯一二级索引是联合索引，所有的索引列都必须进行等值比较
![image-20230406195531796](C:\backup\assets\image-20230406195531796.png)

### ref

通过普通的二级索引列与常量进行等值匹配时来查询某个表，访问类型可能是 ref（匹配到多条记录）
如果匹配的记录较少，则回表的代价还是比较低的，所以可能选择使用索引而不是全表扫描的方式来执行查询

### range

使用索引进行范围查询的类型是 range，比全表扫描好

### index

当我们可以使用索引覆盖，但需要扫描全部的索引记录时，访问类型就是 index
![image-20230406195544740](C:\backup\assets\image-20230406195544740.png)

这里是联合索引，但是查询条件不是最左匹配，无法走索引

即扫描的是索引但是索引其实没有生效

### ALL

全表扫描

## possible_keys&key

possible_keys 表示对某个表执行单表查询时可能用到的索引有哪些
key 表示实际用到的索引有哪些，NULL 代表没有使用索引

## key_len

表示当优化器决定使用某个索引执行查询时，该索引记录的最大长度，计算方式是这样的：

- 对于固定长度类型的索引列，最大长度就是这个固定值
- 对于 VARCHAR(100)【utf8】，最大长度是100 x 3 = 300个字节
- 对于变长字段来说，都会有2个字节的空间来存储该变长列的实际长度
- 如果索引列可以存储 NULL 值，则 key_len 比不可以存储 NULL 值时多1个字节
## rows

如果查询优化器决定使用**全表扫描**，rows 就代表预计需要扫描的行数（不是得到的结果条数）
如果用索引来执行查询时，rows 就代表预计扫描的索引记录行数
![image-20230406195702622](C:\backup\assets\image-20230406195702622.png)

## filtered

代表本次查询完之后被过滤得到的数据占比是多少
比如下图：代表驱动表s1 扫描10573条记录，扇出值是10573 x 33.33 % = 3524.3，说明还要对被驱动表执行大约3524次查询
![image-20230406195716147](C:\backup\assets\image-20230406195716147.png)

## Extra

| xx                    | yy                                                           |
| --------------------- | ------------------------------------------------------------ |
| Using index           | 表示直接访问索引就能够获取到所需要的数据（覆盖索引），不需要通过索引回表 |
| Using join buffer     | 使用了连接缓存，会显示连接查询时 MySQL 选择的查询算法        |
| Using filesort        | 无法利用索引完成的排序操作称为“文件排序”                     |
| Using index condition | 搜索条件中有索引列，但是有部分条件无法使用索引，会根据能用索引的条件先搜索一遍再匹配无法使用索引的条件 |
|                       |                                                              |



# 索引合并（单表）

## Intersection合并&Union合并

Intersection 是交集合并，Union 是并集合并
```sql
SELECT * FROM order_exp WHERE order_no = 'a' AND(OR) expire_time = 'b';
```
![image-20230406201333385](C:\backup\assets\image-20230406201333385.png)

假如这个查询使用索引合并的话，过程如下：
1、从`idx_order_no`索引中取出`order_no='a'`的相关记录
2、从`idx_expire_time`索引中取出`expire_time='b'`的相关记录
3、计算两个结果集中 id 的交集
4、回表，从聚簇索引中把指定 id 值的记录取出来

==为啥不单独使用某个二级索引，回表后再过滤另外的条件呢？==

这里要分析一下两种查询执行方式之间需要的成本代价

只读取一个二级索引的成本：
1、按照某个搜索条件读取一个二级索引
2、回表
3、过滤其他的搜索条件

读取多个二级索引之后取交集成本：
1、按照不同的搜索条件分别读取不同的二级索引
2、主键值取交集
3、最后根据主键值进行回表操作

读取多个二级索引比读取一个二级索引消耗性能，但是大部分情况下读取二级索引的操作是顺序IO而回表操作是随机IO，需要比较两种查询方式消耗的时间了

==数据库什么情况下用合并：二级索引等值匹配==
二级索引列必须是等值匹配的情况
对于联合索引来说，在联合索引中的每个列都必须等值匹配，不能出现只匹配部分列的情况
都是为了取出的结果集是按主键值排序的

```sql
-- 因为对order_no进行了范围匹配
SELECT * FROM order_exp WHERE order_no > 'a' AND expire_time = 'a';
-- 因为insert_time使用到的联合索引u_idx_day_status中的order_status和expire_time列并没有出现在搜索条件中
SELECT * FROM order_exp WHERE order_no = 'a' AND insert_time = 'a';
```
==数据库什么情况下用合并：主键列范围匹配==
因为主键的索引是有序的，按照有序的主键值回表开销不大
PS：二级索引范围查询的话得到的结果不是根据主键排序的，在求主键交集之前需要先排序比较耗时

上边两种情况只是可能发生而不是必然，是否走索引合并得看优化器的心情，优化器预测耗时比较之后抉择

## Sort-Union合并

上述索引合并条件苛刻，必须是等值匹配才行
```sql
SELECT * FROM order_exp WHERE order_no < 'a' OR expire_time > 'z'
```
上面的语句就不能使用 Union 索引合并，因为主键不是排好序的

可以这样做（比 Union 合并多了一步主键排序的过程）
1、根据第一个条件使用索引获取记录，并按照记录的主键值排序
2、根据第二个条件使用索引获取记录，并按照记录的主键值排序
3、主键值求并集
4、回表

也不是必然的，得看优化器的心情

## 联合索引代替Intersection合并

没有 Intersection 合并，可以使用联合索引代替

# 连接查询与优化

```sql
SELECT * FROM e1, e2 WHERE e1.m1 > 1 AND e1.m1 = e2.m2 AND e2.n2 < 'd';
```
连接查询的步骤：
1、确定驱动表，第一个需要查询的表
2、遍历驱动表结果，到被驱动表中查找匹配记录
![image-20230406201205799](C:\backup\assets\image-20230406201205799.png)

上面的例子需要查询1次驱动表、两次被驱动表
==结论：两表连接查询，需要查询1次驱动表、多次被驱动表；小表做驱动表更好==

内连接时：驱动表中的数据只有在被驱动表中有匹配记录，才加入结果集
外连接时：驱动表中的数据即使在被驱动表中没有匹配记录，也需要加入结果集（左连接左表为驱动表、右连接右表为驱动表)

可以优化一下对驱动表的查询，如果可以的话，这里不谈
被驱动表全表扫描很慢，可以在被驱动表的相关字段建立索引（只有二级索引+回表代价比全表扫描低时才走索引）
如果实在不能利用索引，那就要利用好 JoinBuffer（缓冲区），调整合适的缓冲区大小来优化（降低被驱动表的扫描次数）
（PS：只有查询列表的列和查询条件中的列才进入缓冲区，因此一定要杜绝使用`select *`）
![image-20230419225740824](C:\backup\assets\image-20230419225740824.png)

# 做过MySQL优化吗

不是在出现了问题之后再优化，首先需要做一些预防，比如
1、表的创建：可以适当的允许冗余字段，以空间换时间；《字段数据类型的优化》；《创建高性能的索引》
2、通过 profile、慢查询等相关方式来监控 SQL 语句和数据库的状态

出问题的话从执行计划、索引优化、SQL优化、参数调整等方面来调优

# 修改参数生效吗

参数有 session 和 global 级别的，在客户端修改参数重启不会生效，只有在配置文件中配置重启才会生效

# 使用索引一定可以提升效率吗？

1、对于增删改操作，维护索引反而会降低执行速度
2、对于查询操作，如果利用到了索引将会提升效率，但是也有例外
3、有时候走索引反而会降低效率，比如数据量很少的时候，优化器会选择全表扫描

# 介绍一下Page页的结构

Page 是整个 InnoDB 磁盘管理的最小单位

Page 分为几种类型，常见的页类型有数据页（B+tree Node）、Undo页、系统页、事务数据页等

页结构整体上可以分为三大部分：分别为通用部分、存储记录空间、索引部分
==通用部分==：主要指文件头和文件尾，将页的内容封装，通过文件头和文件尾校验的 CheckSum 方式来确保页的传输是完整的
其中比较重要的是在文件头中的`FIL_PAGE_PREV`和`FIL_PAGE_NEXT`字段，通过这两个字段，我们可以找到该页的上一页和下一页，所有页通过这两个字段可以形成一条双向链表
==记录部分==：页的主要作用是存储记录，“最小和最大记录”和“用户记录”部分占了页结构的主要空间；另外当有新的记录插入时，会从空闲空间中进行分配用于存储新记录
==数据目录部分==：数据页中行记录按照主键值由小到大顺序串联成一个单链表，且单链表的链表头为最小记录，链表尾为最大记录；为了更快速地定位到指定的行记录，借助 `Page Directory`使用二分法快速找到需要查找的行记录
![image-20230416115801011](C:\backup\assets\image-20230416115801011.png)

# InnoDB与MyISAM的区别

|          |  InnoDB  |   MyISAM   |
| :------: | :------: | :--------: |
|   事务   |   支持   |   不支持   |
|   外键   |   支持   |   不支持   |
|  行级锁  |   支持   |   不支持   |
|  表级锁  |   支持   |    支持    |
| 索引结构 | 聚簇索引 | 非聚簇索引 |

# 顺序IO&随机IO

一次磁盘IO时间 = 寻道时间 + 旋转延迟 + 数据传送时间

顺序IO 的旋转延迟极低，随机IO 的旋转延迟是随机的可能很高

# B+树能存储多少个索引记录

MySQL B+树的节点大小等于一个页（16K），这样做的目的是每个节点只需要一次 IO 就可以完全载入

假设主键是 bigint 8字节，指针6字节，根节点可以存储索引数量 16k / 14 = 1170，第二层可以存储索引数量 1170 * 1170

假设一行数据是1K，一个叶子节点能存储 16 条数据

三层 B+ 树能够存储  1170 * 1170 * 16 大约 2000万数据

# 查询语句是怎么执行的

![83a5d762-27eb-486e-b22f-193d2bb847dc](C:\backup\assets\83a5d762-27eb-486e-b22f-193d2bb847dc.png)

1、建立连接

解析器：词法分析、语法分析，生成解析树
预处理器：根据一些 MySQL 规则进一步检查解析树是否合法，例如检查数据表和数据列是否存在，还会解析名字和别名，看看它们是否有歧义，最后生成新的解析树
查询优化器：生成并选择最优的执行计划 TODO 具体干啥了
执行器：操作引擎，返回结果

关于查询缓存：5.7支持，8之后废弃

# 更新语句是怎么执行的

看《binlog》

# RedoLog与BinLog的区别

RedoLog 是物理日志，BinLog 是逻辑日志

RedoLog 是 InnoDB 引擎特有的，BinLog 是 MySQL 的 Server 层实现的，所有引擎都可以使用

RedoLog 是循环写的，BinLog 是追加写

用途不一样

# 如何优化深分页

TODO

# 写失效与双写机制

InnoDB 的页（16K）和操作系统的页（4K）大小不一致，InnoDB 一个页写入磁盘需要分4次写
如果写了一半宕机了，这种情况叫做部分写失效，可能会导致数据丢失

双写机制解决了写失效问题
在 BufferPool 的脏页刷新到磁盘前，会先写入磁盘中共享表空间的双写缓冲区（是一个文件相当于备份），完成后再真正刷盘
如果宕机出现数据页损坏，重启后利用双写缓冲区的备份数据修复损坏的数据页，然后再进行 RedoLog 重做

![image-20230426140745132](C:\backup\assets\image-20230426140745132.png)
